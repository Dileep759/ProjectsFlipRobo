{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Malignant Comments Classifier Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dileep759/ProjectsFlipRobo/blob/main/Malignant_Comments_Classifier_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVbTqdx1cEt2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "PcChJMRycOAr",
        "outputId": "3e2c8bb1-83c5-4d8b-bed6-b41e5201ddaa"
      },
      "source": [
        "from google.colab import files\n",
        "  \n",
        "  \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8477eda-33d1-499f-8070-50ce8803fe86\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8477eda-33d1-499f-8070-50ce8803fe86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train1.csv to train1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6t0vZIWxcEt7",
        "outputId": "53b16ed1-ac64-4aed-e5a1-86754f5529f8"
      },
      "source": [
        "df=pd.read_csv(\"train1.csv\")\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>malignant</th>\n",
              "      <th>highly_malignant</th>\n",
              "      <th>rude</th>\n",
              "      <th>threat</th>\n",
              "      <th>abuse</th>\n",
              "      <th>loathe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... loathe\n",
              "0  0000997932d777bf  ...      0\n",
              "1  000103f0d9cfb60f  ...      0\n",
              "2  000113f07ec002fd  ...      0\n",
              "3  0001b41b1c6bb37e  ...      0\n",
              "4  0001d958c54c6e35  ...      0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUh-NZ2OcEt9",
        "outputId": "1ec2e6e9-ddbd-46f7-83c0-af8941705298"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159571, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832fwy3rcEt-",
        "outputId": "231ba7e7-d1b1-4593-ef2f-852b3d59fa57"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id                  object\n",
            "comment_text        object\n",
            "malignant            int64\n",
            "highly_malignant     int64\n",
            "rude                 int64\n",
            "threat               int64\n",
            "abuse                int64\n",
            "loathe               int64\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GMb2tYQcEt_"
      },
      "source": [
        "Hence we have a sufficiently large dataset consistly of 159571 samples. Each sample contains 8 fields.\n",
        "It was observed that running train_test_split on the heavy preprocessed dataframe sometimes resulted in system going out of memory. Hence to avoid such cases, one extra line of code was added. The df.reindex code will shuffle the indices initially, so that later splitting dataset into training and testing will give fairer results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvo6-TSMcEt_"
      },
      "source": [
        "df = df.reindex(np.random.permutation(df.index))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM1YOT71cEuA"
      },
      "source": [
        "# Separate the comment field data and outcome labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjGba2NTcEuB",
        "outputId": "6847f2b3-706d-4ee6-fe73-3385130bfb24"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "comment = df['comment_text']\n",
        "print(comment.head())\n",
        "comment = comment.to_numpy()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "151155    \"This entire article, apart from being a mess,...\n",
            "8335      If you wish to quote higher figure, contact ei...\n",
            "98385     Myth? \\n\\nThis sounds exactly like the myth of...\n",
            "46424     I think most (if not all) of the other UK Sing...\n",
            "82378     Erachima, there is no dramatic conflict going ...\n",
            "Name: comment_text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyIqmmrHcEuB",
        "outputId": "3871534c-8d16-4f55-ae22-481a4843ebaf"
      },
      "source": [
        "label = df[['malignant', 'highly_malignant' , 'rude' , 'threat' , 'abuse' , 'loathe']]\n",
        "print(label.head())\n",
        "label = label.to_numpy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        malignant  highly_malignant  rude  threat  abuse  loathe\n",
            "151155          0                 0     0       0      0       0\n",
            "8335            0                 0     0       0      0       0\n",
            "98385           0                 0     0       0      0       0\n",
            "46424           0                 0     0       0      0       0\n",
            "82378           0                 0     0       0      0       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWx_dx4mcEuC",
        "outputId": "fb1c46ed-183a-4494-e8a9-14787c1fbcc9"
      },
      "source": [
        "df['malignant'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    144277\n",
              "1     15294\n",
              "Name: malignant, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOxykvOScEuD",
        "outputId": "43093246-1802-455e-ee50-9534c92f4f8b"
      },
      "source": [
        "df['highly_malignant'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    157976\n",
              "1      1595\n",
              "Name: highly_malignant, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv8tLRFZcEuD",
        "outputId": "0377355f-c9eb-480b-a32a-e78fb67bc4be"
      },
      "source": [
        "df['rude'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    151122\n",
              "1      8449\n",
              "Name: rude, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INyk2_gpcEuE",
        "outputId": "e9cdbeab-4883-48c2-aad6-af6f2cd8384e"
      },
      "source": [
        "df['threat'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    159093\n",
              "1       478\n",
              "Name: threat, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_5Ztv7mcEuF",
        "outputId": "0b8f0fac-384a-45a9-c938-a7bae6462deb"
      },
      "source": [
        "df['abuse'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    151694\n",
              "1      7877\n",
              "Name: abuse, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "391MLBM5cEuF",
        "outputId": "6c0d0abe-39cd-4e9c-adde-b8685fa6b0e6"
      },
      "source": [
        "df['loathe'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    158166\n",
              "1      1405\n",
              "Name: loathe, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8L9Mv-cEuG"
      },
      "source": [
        "I had a dataset of 159571 samples of comments along with their labels. I observed that every 1 in 10 samples was malignant, every 1 in 17 and 19 samples were rude and abuse respectively, but the occurrences of sample being highly_malignant(1 in 100), threat(1 in 332) and loathe(1 in 112) was extremely rare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqGnShQ2cEuG",
        "outputId": "4fdefd1b-56ca-4eeb-8b81-5fe8dec3aa1b"
      },
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5YUXcyBcEuH"
      },
      "source": [
        "df.drop_duplicates(inplace = True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDCO7-VZcEuH",
        "outputId": "98e3aaf7-2e4b-4256-da52-97e7576a177e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "tzteGLvkcEuH"
      },
      "source": [
        "Let us find out the frequency of occurence of multilabelled data\n",
        "1.ct1 counts samples having atleast one label\n",
        "2.ct2 counts samples having 2 or more than 2 labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-jENuvEcEuI",
        "outputId": "415b0e75-8186-4e33-f553-d9af601c96d1"
      },
      "source": [
        "ct1,ct2 = 0,0\n",
        "for i in range(label.shape[0]):\n",
        "    ct = np.count_nonzero(label[i])\n",
        "    if ct :\n",
        "        ct1 = ct1+1\n",
        "    if ct>1 :\n",
        "        ct2 = ct2+1\n",
        "print(ct1)\n",
        "print(ct2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16225\n",
            "9865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVVZlZwUcEuI"
      },
      "source": [
        "I had a dataset of 159571 samples of comments along with their labels, but I observed that among all these samples of comments there were only 26090 comments with atleast one label non-zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAFBy_9acEuJ"
      },
      "source": [
        "i.e - out of six samples of comments 1 sample has atleast 1 label, which is non-zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBk8GCPpcEuJ"
      },
      "source": [
        "# Data Visualisations\n",
        "Let us analyse the no. of comments having lengths varying from 0 to 1200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "5veB3HkMcEuJ",
        "outputId": "dbabd0be-9ddb-4d65-8ae3-78dc69e7459a"
      },
      "source": [
        "x = [len(comment[i]) for i in range(comment.shape[0])]\n",
        "\n",
        "print('average length of comment: {:.3f}'.format(sum(x)/len(x)) )\n",
        "bins = [1,200,400,600,800,1000,1200]\n",
        "plt.hist(x, bins=bins)\n",
        "plt.xlabel('Length of comments')\n",
        "plt.ylabel('Number of comments')       \n",
        "plt.axis([0, 1200, 0, 90000])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average length of comment: 394.139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlhx8PYRcEuK"
      },
      "source": [
        "From the first visualisation we can observe that comments were of varying lengths from less than 200 characters to 1200 characters. The majority of comments had length up to 200.\n",
        "\n",
        "For the next visualisation, I had length of comments on the independent axis again similar to the previous plot. But instead of counting number of comments, I counted comments belonging to each of the different categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6IJETIVcEuK"
      },
      "source": [
        "Number of comments classified as Malignant, Highly_malignant ,....etc depending on their lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "kQTHT6bvcEuL",
        "outputId": "eafb70ea-b2cf-49af-93dd-50e24b9f7d23"
      },
      "source": [
        "y = np.zeros(label.shape)\n",
        "for ix in range(comment.shape[0]):\n",
        "    l = len(comment[ix])\n",
        "    if label[ix][0] :\n",
        "        y[ix][0] = l\n",
        "    if label[ix][1] :\n",
        "        y[ix][1] = l\n",
        "    if label[ix][2] :\n",
        "        y[ix][2] = l\n",
        "    if label[ix][3] :\n",
        "        y[ix][3] = l\n",
        "    if label[ix][4] :\n",
        "        y[ix][4] = l\n",
        "    if label[ix][5] :\n",
        "        y[ix][5] = l\n",
        "\n",
        "labelsplt = ['malignant','highly_malignant','rude','threat','abuse','loathe']\n",
        "color = ['orange','brown','purple','yellow','teal','chartreuse']        \n",
        "plt.hist(y,bins = bins,label = labelsplt,color = color)\n",
        "plt.axis([0, 1200, 0, 8000])\n",
        "plt.xlabel('Length of comments')\n",
        "plt.ylabel('Number of comments') \n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Pxo_lG7cEuL"
      },
      "source": [
        "From above plot we observe that for all the length of comments Malignant label has highest count followed by rude "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS1xtsqzcEuM"
      },
      "source": [
        "Since including very long length comments for training increased the number of words manifold, the kernel was unable to handle the required memory. It was required to trim the data effectively, so as to not miss essential features and loose accuracy. Setting 400 characters as the threshold included up to 80% of the data and hence appeared to be a good choice. (We had less words in total, but the percentage of toxic words captured were more)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjmKELzHcEuM"
      },
      "source": [
        "comments = []\n",
        "labels = []\n",
        "\n",
        "for ix in range(comment.shape[0]):\n",
        "    if len(comment[ix])<=400:\n",
        "        comments.append(comment[ix])\n",
        "        labels.append(label[ix])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur5hf_BRcEuM"
      },
      "source": [
        "labels = np.asarray(labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwZ62vscEuN",
        "outputId": "191973f1-3f65-4aae-85e8-e0a3ae3bc96b"
      },
      "source": [
        "print(len(comments))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "115893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B2NfRSncEuN"
      },
      "source": [
        "Hence, after removing comments longer than 400 characters, we are still left with more than 115893 comments, which seems enough for training purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRCgRh8EcEuN"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "jfPz4Fz8cEuO"
      },
      "source": [
        "Preprocessing involved the following steps:\n",
        "\n",
        "Removing Punctuations and other special characters\n",
        "Splitting the comments into individual words\n",
        "Removing Stop Words\n",
        "Stemming and Lemmatising\n",
        "Applying Count Vectoriser\n",
        "Splitting dataset into Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SRTMTT_cEuO"
      },
      "source": [
        "# Preparing a string containing all punctuations to be removed\n",
        "The string library contains punctuation characters. This is imported and all numbers are appended to this string. Also, we can notice that our comment_text field contains strings such as won't, didn't, etc which contain apostrophe character('). To prevent these words from being converted to wont/didnt, the character ' represented as \\' in escape sequence notation is replaced by empty character in the punctuation string.\n",
        "\n",
        "maketrans() returns a translation table that maps each character in the punctuation_edit into the character at the same position in the outtab string i.e. it replaces every character in the removal list with a space, since outtab contains a string with spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nWHkSRbcEuP",
        "outputId": "39678072-1207-4770-a4ce-f404dd5ee385"
      },
      "source": [
        "import string\n",
        "print(string.punctuation)\n",
        "punctuation_edit = string.punctuation.replace('\\'','') +\"0123456789\"\n",
        "print (punctuation_edit)\n",
        "outtab = \"                                         \"\n",
        "trantab = str.maketrans(punctuation_edit, outtab)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knhs53UncEuQ",
        "outputId": "af910f50-4baf-4666-d9c7-e0c3d8713af1"
      },
      "source": [
        "!pip install stop-words"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop-words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp37-none-any.whl size=32913 sha256=7ccdcaceeb24b4dee38dd7852c0067d4e112e807e5719254dc883098955b8b78\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXl-KfmZcEuQ"
      },
      "source": [
        "# Updating the list of stop words\n",
        "Stop words are those words that are frequently used in both written and verbal communication and thereby do not have either a positive/negative impact on our statement.E.g. is, this, us,etc.\n",
        "\n",
        "Single letter words if existing or created due to any preprocessing step do not convey any useful meaning and hence can be directly removed. Hence letters from b to z, will be added to the list of stop words imported directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF3HW1UBcEuR"
      },
      "source": [
        "from stop_words import get_stop_words\n",
        "stop_words = get_stop_words('english')\n",
        "stop_words.append('')\n",
        "\n",
        "for x in range(ord('b'), ord('z')+1):\n",
        "    stop_words.append(chr(x))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Im4EqgcEuR",
        "outputId": "b4ee4fa0-9f2d-49e6-aa31-2dca0b0fc442"
      },
      "source": [
        "print (stop_words)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', '', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eCGtYddcEuR"
      },
      "source": [
        "# Stemming and Lemmatizing\n",
        "\n",
        "Stemming is the process of converting inflected/derived words to their word stem or the root form. Basically, a large number of similar origin words are converted to the same word.E.g. words like \"stems\", \"stemmer\", \"stemming\", \"stemmed\" as based on \"stem\". This helps in achieving the training process with a better accuracy.\n",
        "\n",
        "Lemmatizing is the process of grouping together the inflected forms of a word so they can be analysed as a single item. This is quite similar to stemming in its working but differs since it depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence, such as neighboring sentences or even an entire document.\n",
        "\n",
        "The wordnet library in nltk will be used for this purpose. Stemmer and Lemmatizer are also imported from nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmPLAJE3cEuS"
      },
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Ys-YPecEuS"
      },
      "source": [
        "lemmatiser = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icrD1i_ccEuS"
      },
      "source": [
        "# We can now, loop once through all the comments applying :"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "JPXGpy-7cEuT"
      },
      "source": [
        "punctuation removal\n",
        "splitting the words by space\n",
        "applying stemmer and lemmatizer\n",
        "recombining the words again for further processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2igAxUbhOjY",
        "outputId": "aca1cc77-e3a5-49a4-a85b-f7f4483cb45c"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhWe7l9ocEuT"
      },
      "source": [
        "for i in range(len(comments)):\n",
        "    comments[i] = comments[i].lower().translate(trantab)\n",
        "    l = []\n",
        "    for word in comments[i].split():\n",
        "        l.append(stemmer.stem(lemmatiser.lemmatize(word,pos=\"v\")))\n",
        "    comments[i] = \" \".join(l)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3ALDRe0cEuT",
        "outputId": "100a4590-6ac8-41f3-a664-b77cc71f397a"
      },
      "source": [
        "!pip install scikit-learn"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCfxHjkhcEuU"
      },
      "source": [
        "# Applying Count Vectorizer\n",
        "\n",
        "Here we can finally convert our comments into a matrix of token counts, which signifies the number of times it occurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okzdPF39cEuU"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#create object supplying our custom stop words\n",
        "count_vector = CountVectorizer(stop_words=stop_words)\n",
        "#fitting it to converts comments into bag of words format\n",
        "tf = count_vector.fit_transform(comments).astype(np.uint8)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUcI19uAcEuU"
      },
      "source": [
        "tf=tf.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJw-X6_ZcEuV",
        "outputId": "ea8deb40-d6b2-46b5-98e8-53bc4f7072ad"
      },
      "source": [
        "print(tf.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(115893, 72292)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a85NLwxacEuV"
      },
      "source": [
        "Hence from its shape we can imply that after all preprocessing we have a list of 72292 words in total."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYZgOUAacEuV"
      },
      "source": [
        "# Splitting dataset into training and testing\n",
        "\n",
        "Since the system was going out of memory using train_test_split, I had jumbled all the indexes in the beginning itself.\n",
        "\n",
        "The shuffle function defined here performs the task of assigning first 2/3rd values to train and remaining 1/3rd values to the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRvUDg4gcEuW",
        "outputId": "88739a5a-a5fa-41df-d796-b92bae2fe812"
      },
      "source": [
        "def shuffle(matrix, target, test_proportion):\n",
        "    ratio = int(matrix.shape[0]/test_proportion)\n",
        "    X_train = matrix[ratio:,:]\n",
        "    X_test =  matrix[:ratio,:]\n",
        "    Y_train = target[ratio:,:]\n",
        "    Y_test =  target[:ratio,:]\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = shuffle(tf, labels,3)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38631, 72292)\n",
            "(77262, 72292)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsSZGC_ccEuX"
      },
      "source": [
        "# Implementation :\n",
        "    \n",
        "Let us define all the evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuV9RD-mcEuX"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import hamming_loss"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQb5-7CHcEuX"
      },
      "source": [
        "def evaluate_score(Y_test,predict):\n",
        "    accuracy = accuracy_score(Y_test,predict)\n",
        "    print(\"Accuracy : {}\".format(accuracy*100))\n",
        "    \n",
        "    try : \n",
        "        loss = log_loss(Y_test,predict)\n",
        "    except :\n",
        "        loss = log_loss(Y_test,predict.toarray())\n",
        "    print(\"Log_loss : {}\".format(loss))\n",
        "    \n",
        "    loss = hamming_loss(Y_test,predict)\n",
        "    print(\"Hamming_loss : {}\".format(loss*100))\n",
        "    \n",
        "    precision = precision_score(Y_test, predict, average='weighted')\n",
        "    print('Precision: {}'.format(precision*100))\n",
        "    \n",
        "    recall = recall_score(Y_test, predict, average='weighted')\n",
        "    print('Recall: {}'.format(recall*100))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hv4ifPvcEuY"
      },
      "source": [
        "# Starting with the First Model -\n",
        "\n",
        "Problem Transformation Methods :\n",
        "\n",
        "These include the Binary Relevance, Label Powerset and Classifier Chain methods. Implementations of these methods is available in the scikit-multilearn library.\n",
        "\n",
        "I will be implementing the most basic method,which is the Binary Relevance method from scratch. It does not take into account the interdependence of labels and basically creates a separate classifier for each of the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag7tzXD3cEuY",
        "outputId": "7e7e6953-17a4-43fb-d5c8-b00aeec7c442"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |                            | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |                        | 20kB 9.3MB/s eta 0:00:01\r\u001b[K     |                     | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |                 | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |             | 51kB 2.9MB/s eta 0:00:01\r\u001b[K     |          | 61kB 3.2MB/s eta 0:00:01\r\u001b[K     |      | 71kB 3.4MB/s eta 0:00:01\r\u001b[K     |  | 81kB 3.7MB/s eta 0:00:01\r\u001b[K     || 92kB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tL8Wp0McEuZ"
      },
      "source": [
        "## 1. Binary Relevance (BR) Method with MultinomialNB classifiers (from scratch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0TuDt4ycEuZ"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from skmultilearn.problem_transform import BinaryRelevance"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3r2XJmIcEuZ",
        "outputId": "8ebd97e7-ffc9-43e6-cbd2-ff75cc2be51f"
      },
      "source": [
        "classifier=BinaryRelevance(classifier=MultinomialNB(),require_dense=[False,True])\n",
        "classifier.fit(X_train,Y_train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BinaryRelevance(classifier=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                         fit_prior=True),\n",
              "                require_dense=[False, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvzZiB1icEua"
      },
      "source": [
        "predictions=classifier.predict(X_test)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy9D6LiLcEua",
        "outputId": "86c0424a-484a-4bbc-a165-748d41268e31"
      },
      "source": [
        "evaluate_score(Y_test,predictions)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 88.28143201056147\n",
            "Log_loss : 1.8300274053463077\n",
            "Hamming_loss : 3.212877395528634\n",
            "Precision: 62.0566719116894\n",
            "Recall: 59.23774584734536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pkWZB0ecEua"
      },
      "source": [
        "## 2. BR Method with SVM classifier (from scikit-multilearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zAqRcsIcEua",
        "outputId": "969b30aa-a509-4e17-d6cb-2dd34f2676bc"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier2 = BinaryRelevance(classifier = SVC(), require_dense = [False, True])\n",
        "classifier2.fit(X_train, Y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BinaryRelevance(classifier=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                               class_weight=None, coef0=0.0,\n",
              "                               decision_function_shape='ovr', degree=3,\n",
              "                               gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                               probability=False, random_state=None,\n",
              "                               shrinking=True, tol=0.001, verbose=False),\n",
              "                require_dense=[False, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B922VV-scEub"
      },
      "source": [
        "#predictions\n",
        "predictions = classifier2.predict(X_test)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RK8Xy6KcEub",
        "outputId": "13fdb830-2779-4657-fd72-61f3a8d5eadd"
      },
      "source": [
        "evaluate_score(Y_test,predictions)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 90.59045844011287\n",
            "Log_loss : 1.777756978514857\n",
            "Hamming_loss : 2.2840033479157498\n",
            "Precision: 86.27197593852149\n",
            "Recall: 54.87901626338755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrl0KK82cEuc"
      },
      "source": [
        "## Adaptation Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk1ib1M5cEuc"
      },
      "source": [
        "## 3. MLkNN with k=2 (from scikit-multilearn)\n",
        "This is the adapted multi-label version of K Nearest Neighbours. Its implementation is available in the multilearn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9KHlk_VcEuc"
      },
      "source": [
        "#create and fit classifier\n",
        "from skmultilearn.adapt import MLkNN\n",
        "classifier = MLkNN(k=2)\n",
        "classifier.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oRIN_ytcEuc"
      },
      "source": [
        "predictions = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-GwbvXAcEud",
        "outputId": "f98184fd-58a3-4363-fffb-7d3d44c02a34"
      },
      "source": [
        "evaluate_score(Y_test,predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 84.58750744220961\n",
            "Log_loss : 1.2611861880143975\n",
            "Hamming_loss : 4.384216475542095\n",
            "Precision: 50.49687329640824\n",
            "Recall: 46.841430964817185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KN4trAJcEud"
      },
      "source": [
        "## 4. BP-MLL Neural Networks (from scratch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1iATDDQcEud"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MoSXmdtcEue",
        "outputId": "34409de5-6599-44b3-c517-5fbe2fb9537d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, activation='relu', input_dim = X_train.shape[1]))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 289172    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 30        \n",
            "=================================================================\n",
            "Total params: 289,202\n",
            "Trainable params: 289,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5br_FPJRcEue"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEEZbNfDcEue",
        "outputId": "70590d23-04c4-41f2-9dfd-4c74be534b8c"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint  \n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.myneural.h5py', \n",
        "                               verbose=1, save_best_only=True)\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2415/2415 [==============================] - 18s 7ms/step - loss: 0.5555 - accuracy: 0.4830\n",
            "Epoch 2/10\n",
            "2415/2415 [==============================] - 18s 7ms/step - loss: 1.0130 - accuracy: 0.2859\n",
            "Epoch 3/10\n",
            "2415/2415 [==============================] - 17s 7ms/step - loss: 1.3920 - accuracy: 0.0972\n",
            "Epoch 4/10\n",
            "2415/2415 [==============================] - 16s 7ms/step - loss: 1.6073 - accuracy: 0.1244\n",
            "Epoch 5/10\n",
            "2415/2415 [==============================] - 16s 7ms/step - loss: 1.7638 - accuracy: 0.1735\n",
            "Epoch 6/10\n",
            "2415/2415 [==============================] - 18s 7ms/step - loss: 2.0838 - accuracy: 0.4493\n",
            "Epoch 7/10\n",
            "2415/2415 [==============================] - 17s 7ms/step - loss: 2.4751 - accuracy: 0.4448\n",
            "Epoch 8/10\n",
            "2415/2415 [==============================] - 18s 7ms/step - loss: 2.9604 - accuracy: 0.4491\n",
            "Epoch 9/10\n",
            "2415/2415 [==============================] - 20s 8ms/step - loss: 3.4167 - accuracy: 0.4433\n",
            "Epoch 10/10\n",
            "2415/2415 [==============================] - 18s 7ms/step - loss: 4.1124 - accuracy: 0.4240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1fd9f440e20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTrnHw7WcEuf"
      },
      "source": [
        "predict = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqVcP9ZZcEuf",
        "outputId": "aab634bd-0fa3-4d5d-97d0-16ba8075121a"
      },
      "source": [
        "print(predict[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9.6000606e-01 0.0000000e+00 3.9993498e-02 0.0000000e+00 4.0257436e-07\n",
            " 0.0000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bZBPkVacEuf"
      },
      "source": [
        "Since the results returned by the model are in the form of probabilities, they have to be explicitly converted to either 0/1 using the round function. This is because the hamming_loss and accuracy_score cannot work on these values directly. However, log loss can compute loss directly without modifying the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbxPXzEYcEug",
        "outputId": "1f5169bf-d33a-4922-b9de-6279e83acce1"
      },
      "source": [
        "loss = log_loss(Y_test,predict)\n",
        "print(\"Log_loss : {}\".format(loss))\n",
        "predict = np.round(predict)\n",
        "loss = hamming_loss(Y_test,predict)\n",
        "print(\"Hamming_loss : {}\".format(loss*100))\n",
        "accuracy = accuracy_score(Y_test,predict)\n",
        "print(\"Accuracy : {}\".format(accuracy*100))\n",
        "precision = precision_score(Y_test, predict, average='weighted')\n",
        "print('Precision: {}'.format(precision*100))\n",
        "recall = recall_score(Y_test, predict, average='weighted')\n",
        "print('Recall: {}'.format(recall*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log_loss : 4.135400330646042\n",
            "Hamming_loss : 3.345327155220764\n",
            "Accuracy : 88.78361937304237\n",
            "Precision: 38.562623258488706\n",
            "Recall: 25.11786538268633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR6c90qwcEuh"
      },
      "source": [
        "## Let us try improving the BP-MLL model (Refining)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef4tj-BOcEuh"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "#define parameters for using in param grid\n",
        "nodes = [16, 32] # number of nodes in the hidden layer\n",
        "lrs = [0.001, 0.002] # learning rate, default = 0.001\n",
        "epochs = [10,20]\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSHhvIcUcEuh"
      },
      "source": [
        "def create_model(nodes=10,lr=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(nodes, activation='relu', input_dim = X_train.shape[1]))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(6, activation='softmax'))\n",
        "    opt = optimizers.RMSprop(lr=lr)\n",
        "    model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeX9ovGecEui",
        "outputId": "c00f9410-c688-4175-835b-af1f1c32297b"
      },
      "source": [
        "#start fitting process\n",
        "param_grid = dict(epochs=epochs,nodes=nodes, lr=lrs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,refit=True,verbose=2)\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 0.6353 - accuracy: 0.2676\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 1.2377 - accuracy: 0.2767\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 1.7022 - accuracy: 0.2772\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 2.2915 - accuracy: 0.2778\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 3.1121 - accuracy: 0.3373\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 51s 26ms/step - loss: 4.1894 - accuracy: 0.3502\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 56s 29ms/step - loss: 5.4490 - accuracy: 0.3595\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 53s 28ms/step - loss: 6.7750 - accuracy: 0.3109\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 8.4653 - accuracy: 0.3806\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 52s 27ms/step - loss: 10.4309 - accuracy: 0.3770\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 11.5071 - accuracy: 0.1041\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=16; total time= 8.3min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 54s 28ms/step - loss: 0.6961 - accuracy: 0.3119\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 52s 27ms/step - loss: 1.2730 - accuracy: 0.2792\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.5939 - accuracy: 0.2670\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.5372 - accuracy: 0.2408\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 1.5050 - accuracy: 0.2863\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 45s 24ms/step - loss: 1.5458 - accuracy: 0.3420\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 54s 28ms/step - loss: 1.7523 - accuracy: 0.3417\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.0538 - accuracy: 0.3794\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 2.3659 - accuracy: 0.4084\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 2.6546 - accuracy: 0.4691\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 3.0888 - accuracy: 0.2688\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=16; total time= 8.2min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 0.6344 - accuracy: 0.4967\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 51s 27ms/step - loss: 1.2428 - accuracy: 0.2812\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 50s 26ms/step - loss: 1.7508 - accuracy: 0.2471\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 2.2606 - accuracy: 0.2889\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.9329 - accuracy: 0.2992\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 3.7885 - accuracy: 0.2709\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 4.8675 - accuracy: 0.3023\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 6.0582 - accuracy: 0.3127\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 7.5315 - accuracy: 0.3543\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 9.0174 - accuracy: 0.4460\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 10.0917 - accuracy: 0.4372\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=16; total time= 8.1min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 0.7331 - accuracy: 0.2676\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.3522 - accuracy: 0.2642\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.4363 - accuracy: 0.2610\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.1632 - accuracy: 0.2709\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 55s 28ms/step - loss: 1.1288 - accuracy: 0.3289\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 55s 29ms/step - loss: 1.3524 - accuracy: 0.4111\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 54s 28ms/step - loss: 1.8140 - accuracy: 0.4516\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 2.2712 - accuracy: 0.4811\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.7951 - accuracy: 0.5113\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 3.2832 - accuracy: 0.5429\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 3.1031 - accuracy: 0.0511\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=16; total time= 8.4min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 0.6259 - accuracy: 0.4255\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.3621 - accuracy: 0.3104\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.0151 - accuracy: 0.3384\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.7366 - accuracy: 0.2856\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 51s 26ms/step - loss: 3.7207 - accuracy: 0.2829\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 53s 27ms/step - loss: 5.0722 - accuracy: 0.3013\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 52s 27ms/step - loss: 6.8360 - accuracy: 0.2952\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 54s 28ms/step - loss: 8.6634 - accuracy: 0.3197\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 10.5985 - accuracy: 0.3197\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 13.2230 - accuracy: 0.3074\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 13.1943 - accuracy: 0.9769\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=16; total time= 8.3min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 0.7172 - accuracy: 0.2751\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 1.5420 - accuracy: 0.2686\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 2.2791 - accuracy: 0.2712\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 3.2147 - accuracy: 0.2881\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 4.6557 - accuracy: 0.3302\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 6.4421 - accuracy: 0.5030\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 8.7170 - accuracy: 0.5606\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 11.1335 - accuracy: 0.5196\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 14.3827 - accuracy: 0.5218\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 17.3500 - accuracy: 0.5089\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 19.2013 - accuracy: 0.9949\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=32; total time=14.7min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 0.7547 - accuracy: 0.2528\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 1.4852 - accuracy: 0.2639\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 1.8374 - accuracy: 0.2636\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 2.1139 - accuracy: 0.2777\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 2.6840 - accuracy: 0.3394\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 3.6229 - accuracy: 0.4678\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 4.6841 - accuracy: 0.5632\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 5.9508 - accuracy: 0.5146\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 7.6552 - accuracy: 0.5073\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 9.3392 - accuracy: 0.4629\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 11.3003 - accuracy: 0.0498\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=32; total time=14.7min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 84s 44ms/step - loss: 0.7925 - accuracy: 0.3064\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 86s 44ms/step - loss: 1.7362 - accuracy: 0.2681\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 2.4857 - accuracy: 0.2703\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 84s 44ms/step - loss: 3.2548 - accuracy: 0.2971\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 4.6458 - accuracy: 0.4526\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 86s 44ms/step - loss: 6.2578 - accuracy: 0.5317\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 8.3225 - accuracy: 0.5089\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 10.7539 - accuracy: 0.5083\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 13.4541 - accuracy: 0.5111\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 16.2011 - accuracy: 0.4825\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 18.6737 - accuracy: 0.0931\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=32; total time=14.6min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 0.7590 - accuracy: 0.3869\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 1.6843 - accuracy: 0.2691\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 2.3036 - accuracy: 0.2485\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 3.0876 - accuracy: 0.2202\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 4.2419 - accuracy: 0.2938\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 5.7971 - accuracy: 0.4986\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 7.8205 - accuracy: 0.5419\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 86s 44ms/step - loss: 10.2276 - accuracy: 0.5079\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 12.4172 - accuracy: 0.4977\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 15.3847 - accuracy: 0.4743\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 14.8140 - accuracy: 0.9943\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=32; total time=14.6min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 0.7134 - accuracy: 0.3089\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 1.4057 - accuracy: 0.2694\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 1.8610 - accuracy: 0.2673\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 2.4027 - accuracy: 0.3130\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 96s 50ms/step - loss: 3.0579 - accuracy: 0.3453\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 3.9461 - accuracy: 0.4281\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 5.0454 - accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 6.3077 - accuracy: 0.5059\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 7.8538 - accuracy: 0.4760\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 9.5295 - accuracy: 0.4569\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 9.7988 - accuracy: 0.1002\n",
            "[CV] END ......................epochs=10, lr=0.001, nodes=32; total time=15.1min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 1.0598 - accuracy: 0.2773\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.3701 - accuracy: 0.27770s - loss: 1.3710 - accuracy: \n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.6655 - accuracy: 0.4304\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 2.5687 - accuracy: 0.5090\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 3.7835 - accuracy: 0.4556\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 5.1218 - accuracy: 0.4228\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 6.6818 - accuracy: 0.3922\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 8.8060 - accuracy: 0.3668\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 10.6898 - accuracy: 0.3597\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 13.5095 - accuracy: 0.3415\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 14.9148 - accuracy: 0.0131\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=16; total time= 8.0min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 0.8859 - accuracy: 0.2725\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.3286 - accuracy: 0.2932\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.6709 - accuracy: 0.4215\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.5876 - accuracy: 0.5434\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 3.8702 - accuracy: 0.4993\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 5.4434 - accuracy: 0.4689\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 49s 26ms/step - loss: 7.5743 - accuracy: 0.4331\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 51s 26ms/step - loss: 9.9986 - accuracy: 0.3860\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 12.6830 - accuracy: 0.3833\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 15.5683 - accuracy: 0.3620\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 18.7614 - accuracy: 0.0182\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=16; total time= 8.1min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 0.8722 - accuracy: 0.3195\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 1.2760 - accuracy: 0.2613\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.7475 - accuracy: 0.4505\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 2.5035 - accuracy: 0.5034\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 49s 26ms/step - loss: 3.7243 - accuracy: 0.4599\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 5.0140 - accuracy: 0.4064\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 6.7626 - accuracy: 0.3805\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 8.5138 - accuracy: 0.3738\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 49s 26ms/step - loss: 11.0940 - accuracy: 0.3622\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 50s 26ms/step - loss: 12.8316 - accuracy: 0.3475\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 15.0594 - accuracy: 0.0095\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=16; total time= 8.2min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 50s 26ms/step - loss: 0.9571 - accuracy: 0.3024\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.5633 - accuracy: 0.2841\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 2.3905 - accuracy: 0.4049\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 3.7939 - accuracy: 0.4869\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 5.4883 - accuracy: 0.4587\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 7.2515 - accuracy: 0.4214\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 10.0423 - accuracy: 0.3932\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 12.8191 - accuracy: 0.3789\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 16.1477 - accuracy: 0.3645\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 20.2014 - accuracy: 0.3466\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 19.0831 - accuracy: 0.0546\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=16; total time= 7.8min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 1.0197 - accuracy: 0.3171\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 1.9996 - accuracy: 0.2898\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 51s 27ms/step - loss: 3.1208 - accuracy: 0.4014\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 5.2357 - accuracy: 0.5149\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 8.1632 - accuracy: 0.4785\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 11.7184 - accuracy: 0.4850\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 15.6890 - accuracy: 0.4571\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 20.1266 - accuracy: 0.4131\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 25.6405 - accuracy: 0.3932\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 32.1300 - accuracy: 0.3747\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 32.5656 - accuracy: 0.0194\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=16; total time= 8.0min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 1.2501 - accuracy: 0.3467\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 3.0123 - accuracy: 0.3131\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 6.0810 - accuracy: 0.4601\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 11.0216 - accuracy: 0.4336\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 17.5021 - accuracy: 0.3969\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 25.3464 - accuracy: 0.3624 2s\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 33.8390 - accuracy: 0.3481 6s - loss: 33.5328 - accuracy: 0.347 - ETA: 5s - loss - ETA: 0s - loss: 33.8990 - accuracy: 0.3\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 44.7799 - accuracy: 0.3265\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 57.5626 - accuracy: 0.3236\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 103s 54ms/step - loss: 69.6115 - accuracy: 0.31367s - - ETA: 4 - ETA: 2s - l\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 77.0815 - accuracy: 0.0021\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=32; total time=15.1min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 0.9893 - accuracy: 0.2863\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 2.0564 - accuracy: 0.2713\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 94s 49ms/step - loss: 3.7604 - accuracy: 0.4206\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 6.3453 - accuracy: 0.4123\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 82s 43ms/step - loss: 9.7866 - accuracy: 0.3497\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 14.0806 - accuracy: 0.3446\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 19.3180 - accuracy: 0.3228\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 84s 43ms/step - loss: 25.5243 - accuracy: 0.3024\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 32.1519 - accuracy: 0.2979\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 38.8775 - accuracy: 0.2896\n",
            "  1/483 [..............................] - ETA: 0s - loss: 166.1435 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0065s). Check your callbacks.\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 46.8173 - accuracy: 0.0349\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=32; total time=15.2min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 104s 54ms/step - loss: 1.1363 - accuracy: 0.2784\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 2.0640 - accuracy: 0.2801\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 3.6281 - accuracy: 0.4083\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 6.4535 - accuracy: 0.3640\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 9.7637 - accuracy: 0.3626\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 14.5222 - accuracy: 0.3474 2s - loss: 14.5754 - ETA: 1s - loss: 14.574\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 19.5878 - accuracy: 0.3212 0s - loss: 19.5639 - accur\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 98s 51ms/step - loss: 25.4592 - accuracy: 0.3113 3s - loss: 25.1705 - accuracy: 0.31 -  - ETA: 1s - loss: 25 - ETA: 0s - loss: 25.4666 - accuracy: 0.31\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 32.3663 - accuracy: 0.2959\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 40.6546 - accuracy: 0.2923 2s\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 45.8399 - accuracy: 0.9928\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=32; total time=15.2min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 1.1329 - accuracy: 0.2786\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 2.5520 - accuracy: 0.2732\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 115s 60ms/step - loss: 4.9281 - accuracy: 0.3135\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 116s 60ms/step - loss: 8.5211 - accuracy: 0.4360s - loss: 8.4517 - accuracy\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 104s 54ms/step - loss: 13.6177 - accuracy: 0.38840s - loss: 13.6177 - accuracy: 0.388\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 20.1132 - accuracy: 0.3637\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 27.8925 - accuracy: 0.3374\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 36.2434 - accuracy: 0.3232\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 46.3559 - accuracy: 0.3036\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 56.1344 - accuracy: 0.2981\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 54.3731 - accuracy: 0.0256\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=32; total time=16.0min\n",
            "Epoch 1/10\n",
            "1932/1932 [==============================] - 98s 51ms/step - loss: 1.1182 - accuracy: 0.3095\n",
            "Epoch 2/10\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 1.9640 - accuracy: 0.2879\n",
            "Epoch 3/10\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 3.4839 - accuracy: 0.36831s - ETA: 0s - loss: 3.4883 - accuracy - ETA: 0s - loss: 3.4839 - accuracy: 0.36\n",
            "Epoch 4/10\n",
            "1932/1932 [==============================] - 104s 54ms/step - loss: 6.3014 - accuracy: 0.3928\n",
            "Epoch 5/10\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 9.6083 - accuracy: 0.3641\n",
            "Epoch 6/10\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 13.9526 - accuracy: 0.3403\n",
            "Epoch 7/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 19.0536 - accuracy: 0.3182 0s - loss: 19.0515 - acc\n",
            "Epoch 8/10\n",
            "1932/1932 [==============================] - 86s 44ms/step - loss: 25.2457 - accuracy: 0.3054\n",
            "Epoch 9/10\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 31.6889 - accuracy: 0.2951\n",
            "Epoch 10/10\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 38.8282 - accuracy: 0.2916\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 39.9992 - accuracy: 0.9950\n",
            "[CV] END ......................epochs=10, lr=0.002, nodes=32; total time=15.1min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 0.6972 - accuracy: 0.3701\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 1.5031 - accuracy: 0.2668\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 1.9870 - accuracy: 0.2628\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.3066 - accuracy: 0.2543\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.9770 - accuracy: 0.30020s - loss: 2.9743 - accuracy: \n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 4.0083 - accuracy: 0.3845\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 5.3108 - accuracy: 0.4096\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 6.6551 - accuracy: 0.3894\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 8.4482 - accuracy: 0.4274\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 10.3740 - accuracy: 0.4890\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 12.3369 - accuracy: 0.5035\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 14.7314 - accuracy: 0.5920\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 17.3513 - accuracy: 0.5954\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 19.8327 - accuracy: 0.5825\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 22.6977 - accuracy: 0.5773\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 25.1666 - accuracy: 0.5453\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 28.6943 - accuracy: 0.5442\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 31.7239 - accuracy: 0.5370\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 34.7480 - accuracy: 0.5278\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 38.5257 - accuracy: 0.5193\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 41.0270 - accuracy: 0.0322\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=16; total time=15.7min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 0.7330 - accuracy: 0.2680\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.4063 - accuracy: 0.2672\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.5487 - accuracy: 0.2691\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.4546 - accuracy: 0.2746\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.5378 - accuracy: 0.2947\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.8489 - accuracy: 0.3905\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.4223 - accuracy: 0.4199\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.9834 - accuracy: 0.4703\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 3.5835 - accuracy: 0.5199\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 4.2525 - accuracy: 0.5368\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 5.0215 - accuracy: 0.5472\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 5.7267 - accuracy: 0.4944\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 6.7642 - accuracy: 0.5124\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 7.7843 - accuracy: 0.4927\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 8.8627 - accuracy: 0.4866\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 9.7831 - accuracy: 0.4844\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 10.9011 - accuracy: 0.4505\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 11.8538 - accuracy: 0.4625\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 13.0445 - accuracy: 0.4491\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 14.5053 - accuracy: 0.4255\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 16.5657 - accuracy: 0.9926\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=16; total time=15.7min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 0.5920 - accuracy: 0.2537\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 0.9870 - accuracy: 0.2669\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.3104 - accuracy: 0.2498\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.6900 - accuracy: 0.2325\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.3213 - accuracy: 0.2866\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.9397 - accuracy: 0.2994\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 3.7998 - accuracy: 0.3496\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 4.7854 - accuracy: 0.4600\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 5.6521 - accuracy: 0.5021\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 6.9323 - accuracy: 0.5326\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 8.3313 - accuracy: 0.5637\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 9.6621 - accuracy: 0.5813\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 11.3546 - accuracy: 0.5444\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 13.1831 - accuracy: 0.5498\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 14.5319 - accuracy: 0.5497\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 16.8001 - accuracy: 0.5260\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 19.0506 - accuracy: 0.5094\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 20.8395 - accuracy: 0.5086\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 23.0004 - accuracy: 0.4925\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 25.7996 - accuracy: 0.4912\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 28.0576 - accuracy: 0.0488\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=16; total time=15.7min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 0.6531 - accuracy: 0.3869\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 1.2120 - accuracy: 0.2779\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 1.6699 - accuracy: 0.2594\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.0950 - accuracy: 0.2491\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 2.6953 - accuracy: 0.2263\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 3.3576 - accuracy: 0.2735\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 4.1886 - accuracy: 0.3439\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 5.4530 - accuracy: 0.4092\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 6.6363 - accuracy: 0.4284\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 7.9288 - accuracy: 0.4703\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 9.4114 - accuracy: 0.5231\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 52s 27ms/step - loss: 10.6921 - accuracy: 0.5275\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 12.3954 - accuracy: 0.5276\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 14.3917 - accuracy: 0.5211\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 16.9593 - accuracy: 0.5245\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 18.7412 - accuracy: 0.5304\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 20.5581 - accuracy: 0.5050\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 23.7189 - accuracy: 0.4994\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 25.9106 - accuracy: 0.5063\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 27.6019 - accuracy: 0.4898\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 25.7446 - accuracy: 0.0084\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=16; total time=16.0min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 0.6217 - accuracy: 0.3373\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.1305 - accuracy: 0.2552\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.3455 - accuracy: 0.2502\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.5547 - accuracy: 0.2297\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 1.9034 - accuracy: 0.3310\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 2.3715 - accuracy: 0.2946\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 3.0098 - accuracy: 0.3539\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 3.8314 - accuracy: 0.4209\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 4.5704 - accuracy: 0.4067\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 5.5189 - accuracy: 0.5176\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 6.6749 - accuracy: 0.5513\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 7.6297 - accuracy: 0.5471\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 9.0392 - accuracy: 0.5509\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 10.2399 - accuracy: 0.5401\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 11.8139 - accuracy: 0.5303\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 13.2086 - accuracy: 0.5236\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 14.7754 - accuracy: 0.5162\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 16.8682 - accuracy: 0.4988\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 18.3071 - accuracy: 0.4869\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 20.2474 - accuracy: 0.4758\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 19.6479 - accuracy: 0.9950\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=16; total time=16.0min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 0.7216 - accuracy: 0.2880\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 1.3291 - accuracy: 0.2745\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 1.5104 - accuracy: 0.2682\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 1.6323 - accuracy: 0.2537\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 2.1375 - accuracy: 0.3345\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 2.8793 - accuracy: 0.3340\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 3.7738 - accuracy: 0.3421\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 4.8582 - accuracy: 0.4287\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 6.1003 - accuracy: 0.4659\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 7.2837 - accuracy: 0.4538\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 94s 49ms/step - loss: 8.9035 - accuracy: 0.4293\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 94s 49ms/step - loss: 10.4171 - accuracy: 0.4215\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 12.3789 - accuracy: 0.4012\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 14.3585 - accuracy: 0.3803\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 16.3628 - accuracy: 0.3833\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 18.8484 - accuracy: 0.3709 \n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 20.8044 - accuracy: 0.3648\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 23.3704 - accuracy: 0.3580\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 25.9295 - accuracy: 0.3485\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 29.3174 - accuracy: 0.3413\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 30.7914 - accuracy: 0.2412\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=32; total time=29.9min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 0.7680 - accuracy: 0.2798\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 1.5314 - accuracy: 0.2642\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 1.5819 - accuracy: 0.2644\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 1.3584 - accuracy: 0.2899\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 1.5237 - accuracy: 0.3607\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 1.9068 - accuracy: 0.4784\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 2.5449 - accuracy: 0.5390\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 3.2083 - accuracy: 0.5146\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 4.2181 - accuracy: 0.4996\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 5.2141 - accuracy: 0.4667\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 6.3562 - accuracy: 0.4327\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 7.5729 - accuracy: 0.4140\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 9.3823 - accuracy: 0.4046\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 10.8882 - accuracy: 0.3858\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 12.4140 - accuracy: 0.3869 0s - loss: 12.4213 - accuracy\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 14.2413 - accuracy: 0.3705\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 16.3145 - accuracy: 0.3705\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 18.8216 - accuracy: 0.3594\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 21.1002 - accuracy: 0.3447\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 23.6681 - accuracy: 0.3464\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 27.3252 - accuracy: 0.9944\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=32; total time=30.2min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 0.7347 - accuracy: 0.3718\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 1.4020 - accuracy: 0.2681\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 1.7865 - accuracy: 0.2603\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 2.1795 - accuracy: 0.2733\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 2.9972 - accuracy: 0.33950s - loss: 2.9987 - ac\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 4.0393 - accuracy: 0.4611\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 5.3127 - accuracy: 0.5310\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 7.0341 - accuracy: 0.5032\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 8.6397 - accuracy: 0.49740s - loss:\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 10.4039 - accuracy: 0.4741\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 12.7224 - accuracy: 0.4445\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 14.9998 - accuracy: 0.4195 0s - loss: 15.0054 - acc\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 17.8611 - accuracy: 0.4156 5s - los\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 20.3025 - accuracy: 0.3959\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 23.2625 - accuracy: 0.3946\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 26.9541 - accuracy: 0.3850 1s - loss:  - ETA: 0s - loss: 26.9636 - accuracy: 0.\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 30.4829 - accuracy: 0.3755 1s - loss: 30.\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 34.1944 - accuracy: 0.3639\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 37.7411 - accuracy: 0.3659\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 42.2551 - accuracy: 0.3563 1s - loss: 42.05\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 45.7601 - accuracy: 0.0251\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=32; total time=30.1min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 0.7286 - accuracy: 0.4033\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 1.6503 - accuracy: 0.2841\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 2.3368 - accuracy: 0.2712\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 3.2701 - accuracy: 0.2632\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 92s 47ms/step - loss: 4.6820 - accuracy: 0.3015\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 6.4880 - accuracy: 0.4848\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 8.8589 - accuracy: 0.4531\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 11.3968 - accuracy: 0.4955\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 14.6044 - accuracy: 0.4507 0s - loss: 14.4945 - accurac\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 18.0787 - accuracy: 0.4318\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 92s 47ms/step - loss: 21.9227 - accuracy: 0.4648\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 92s 47ms/step - loss: 26.1488 - accuracy: 0.4777\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 30.7298 - accuracy: 0.4583\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 35.9646 - accuracy: 0.4446\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 40.1626 - accuracy: 0.4228\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 46.9940 - accuracy: 0.4246\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 92s 47ms/step - loss: 51.9614 - accuracy: 0.4131\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 58.5310 - accuracy: 0.3834\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 92s 47ms/step - loss: 66.0026 - accuracy: 0.4021\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 73.5061 - accuracy: 0.3870 1s - loss: 73.7262  - ETA: 0s - loss: 73.4613 - accura\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 67.6165 - accuracy: 0.0151\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=32; total time=30.7min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 0.7791 - accuracy: 0.2844\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 1.6342 - accuracy: 0.2644\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 92s 47ms/step - loss: 2.0673 - accuracy: 0.2599\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 2.5896 - accuracy: 0.2748\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 3.6899 - accuracy: 0.3480\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 5.0011 - accuracy: 0.4509\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 6.7758 - accuracy: 0.5342\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 8.6343 - accuracy: 0.4465\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 10.9188 - accuracy: 0.4676 \n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 13.3522 - accuracy: 0.4782\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 82s 43ms/step - loss: 16.1552 - accuracy: 0.4762\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 19.1415 - accuracy: 0.4617\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 22.6240 - accuracy: 0.4353\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 26.0929 - accuracy: 0.4183\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 29.5293 - accuracy: 0.4103\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 84s 44ms/step - loss: 33.8174 - accuracy: 0.3984\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 38.4158 - accuracy: 0.3914\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 43.2833 - accuracy: 0.3878\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 47.7476 - accuracy: 0.3793\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 92s 47ms/step - loss: 53.3563 - accuracy: 0.3673\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 52.3032 - accuracy: 0.0189\n",
            "[CV] END ......................epochs=20, lr=0.001, nodes=32; total time=29.1min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 50s 26ms/step - loss: 1.0456 - accuracy: 0.26960s - loss: 1.0416 - ac\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 52s 27ms/step - loss: 2.0307 - accuracy: 0.2451\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 3.6151 - accuracy: 0.4247\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 6.1871 - accuracy: 0.6316\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 9.6731 - accuracy: 0.6004\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - ETA: 0s - loss: 13.9352 - accuracy: 0.5454- ETA: 1s - loss: 13.8334 - accura - ETA: 0s - loss: 14.0250 - - 43s 22ms/step - loss: 13.9315 - accuracy: 0.5453\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 19.0326 - accuracy: 0.4936\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 25.6538 - accuracy: 0.4544\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 59s 30ms/step - loss: 33.1902 - accuracy: 0.4280\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 40.4721 - accuracy: 0.4071\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 64s 33ms/step - loss: 50.1871 - accuracy: 0.3953 3s - loss: 49.5 - ETA: 1s - loss: 4\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 59.4706 - accuracy: 0.3787\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 70.9271 - accuracy: 0.3670\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 45s 24ms/step - loss: 81.3857 - accuracy: 0.3528 0s - loss: 81.2567 - accuracy: 0.35\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 93.6131 - accuracy: 0.3458\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 106.3543 - accuracy: 0.3374\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 119.1173 - accuracy: 0.3261\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 133.6060 - accuracy: 0.3194\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 150.1271 - accuracy: 0.31651s - loss: 150.5677 - ac - ETA: 1s - loss: 150.0855 - accuracy: 0.31 - ETA\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 160.5637 - accuracy: 0.3116\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 172.0250 - accuracy: 0.0461\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=16; total time=16.4min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 0.9851 - accuracy: 0.3093\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 1.8088 - accuracy: 0.2772\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 3.0110 - accuracy: 0.40130s - loss: 3.0072 - accura\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 4.9366 - accuracy: 0.5776\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 7.2142 - accuracy: 0.5171\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 51s 26ms/step - loss: 10.4827 - accuracy: 0.4681\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 14.1139 - accuracy: 0.4327\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 18.4252 - accuracy: 0.4098 1s - loss: 18\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 24.0460 - accuracy: 0.3862\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 28.6641 - accuracy: 0.3737 - ETA: 1s - loss: 28.9553\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 36.0681 - accuracy: 0.3597\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 41.8608 - accuracy: 0.3445\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 50.2111 - accuracy: 0.3319 \n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 57.5387 - accuracy: 0.3284\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 66.3131 - accuracy: 0.3214\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 72.4294 - accuracy: 0.3164 7s -\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 84.4915 - accuracy: 0.3083\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 90.5362 - accuracy: 0.3028\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 103.5828 - accuracy: 0.3028\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 41s 21ms/step - loss: 113.7907 - accuracy: 0.3008\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 130.6161 - accuracy: 0.9944\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=16; total time=14.9min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 0.8121 - accuracy: 0.3012\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 75s 39ms/step - loss: 1.7524 - accuracy: 0.3240\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 69s 36ms/step - loss: 3.4295 - accuracy: 0.40252s - loss: 3.444\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 68s 35ms/step - loss: 6.0401 - accuracy: 0.4961: 43s - loss: 4.4093 - accuracy: 0.5 - ETA: 42s - lo\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - ETA: 0s - loss: 9.1674 - accuracy: 0.5387 ETA: 1s - ETA: 0s - loss: 9.1528 -  - 69s 36ms/step - loss: 9.1650 - accuracy: 0.5388\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 64s 33ms/step - loss: 13.2042 - accuracy: 0.5230\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 17.8841 - accuracy: 0.4904\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 55s 28ms/step - loss: 24.7242 - accuracy: 0.4542\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 31.3290 - accuracy: 0.4477\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 66s 34ms/step - loss: 38.7970 - accuracy: 0.3993 0s - loss: 38.8023 - accuracy: 0.39\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 70s 36ms/step - loss: 46.5126 - accuracy: 0.3839 5s - l - ETA: 3s - loss: 45.65 - ETA: 1s - loss: 46. - ETA: 0s - loss: 46.4252 - accuracy: 0.3\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 70s 36ms/step - loss: 56.0565 - accuracy: 0.3841\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 68s 35ms/step - loss: 67.6588 - accuracy: 0.3572 1s - loss: 67.54\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 78.1807 - accuracy: 0.3500\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 89.5364 - accuracy: 0.3498\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 100.4828 - accuracy: 0.33210s - loss: 100.6017 \n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 112.7548 - accuracy: 0.3281\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 129.9057 - accuracy: 0.3295\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 143.8361 - accuracy: 0.3180\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 156.0911 - accuracy: 0.3117\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 172.9007 - accuracy: 0.0104\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=16; total time=18.7min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 1.0420 - accuracy: 0.2980\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 1.7310 - accuracy: 0.28875s - loss: - ETA: 4s - loss:\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 2.7696 - accuracy: 0.4558\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 4.5034 - accuracy: 0.5517\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 49s 25ms/step - loss: 6.9463 - accuracy: 0.48870s - loss: 6.9516 - accuracy: 0.48\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 9.5206 - accuracy: 0.4648\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 12.9726 - accuracy: 0.4222 1s - loss: 12\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 16.9685 - accuracy: 0.3902\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 21.1927 - accuracy: 0.3944  - ETA: 4s -  - E - ETA: 0s - loss: 21.1988 - accuracy: 0.394\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - ETA: 0s - loss: 25.4393 - accuracy: 0.368 - 46s 24ms/step - loss: 25.4188 - accuracy: 0.3682\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 51s 26ms/step - loss: 31.4941 - accuracy: 0.3495\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 36.2413 - accuracy: 0.3400\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 50s 26ms/step - loss: 43.3189 - accuracy: 0.3319\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 49.2584 - accuracy: 0.3182\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 55.1109 - accuracy: 0.3114\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 45s 23ms/step - loss: 65.7757 - accuracy: 0.2994 0s - loss: 65.5308 - ac\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 72.4325 - accuracy: 0.3031 0s - loss: 72.2714 - accura\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 46s 24ms/step - loss: 79.1564 - accuracy: 0.3002\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 86.1763 - accuracy: 0.2942 0s - loss: 86.1948 - accuracy: 0.29\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 44s 23ms/step - loss: 95.0748 - accuracy: 0.2895\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 90.2495 - accuracy: 0.0055\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=16; total time=15.3min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 0.9200 - accuracy: 0.2893\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 1.4955 - accuracy: 0.2811\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 2.3229 - accuracy: 0.3031\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 42s 22ms/step - loss: 3.6508 - accuracy: 0.4906\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 43s 22ms/step - loss: 5.3425 - accuracy: 0.44860s - loss: 5\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 7.4077 - accuracy: 0.3767\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 9.8817 - accuracy: 0.4034\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 12.2693 - accuracy: 0.3946\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 15.4321 - accuracy: 0.3661\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 19.0561 - accuracy: 0.3601\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 23.2254 - accuracy: 0.3389\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 27.0710 - accuracy: 0.3359 0s - loss: 27.0710 - accuracy: 0.335\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 31.5428 - accuracy: 0.3244\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 36.6731 - accuracy: 0.3107\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 41.4739 - accuracy: 0.3103\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 47.5011 - accuracy: 0.3044\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 48s 25ms/step - loss: 54.8410 - accuracy: 0.2958\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 60.9765 - accuracy: 0.2980\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 47s 25ms/step - loss: 66.0341 - accuracy: 0.2901 1s - los\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 47s 24ms/step - loss: 72.3235 - accuracy: 0.2860\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 70.5979 - accuracy: 0.9950\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=16; total time=15.4min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 0.9987 - accuracy: 0.2770\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 2.5399 - accuracy: 0.2593\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 5.0452 - accuracy: 0.3694\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 8.9586 - accuracy: 0.4439\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 14.3309 - accuracy: 0.3911\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 84s 43ms/step - loss: 20.2943 - accuracy: 0.3655\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 28.0230 - accuracy: 0.3445 0s - loss: 28.0171 - accuracy: 0.34\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 35.8669 - accuracy: 0.3230\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 46.7369 - accuracy: 0.3113 5s\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 57.0773 - accuracy: 0.3045\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 70.1933 - accuracy: 0.2943\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 81.8270 - accuracy: 0.2887\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 95.2983 - accuracy: 0.2869 0s - loss: 95.4364 - accuracy: 0.286 - ETA: 0s - loss: 95.3873 - accuracy: 0.\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 110.8624 - accuracy: 0.2814\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 80s 42ms/step - loss: 129.5446 - accuracy: 0.2756\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 79s 41ms/step - loss: 144.9999 - accuracy: 0.2756\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 163.3876 - accuracy: 0.2719\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 181.1269 - accuracy: 0.2687\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 202.9589 - accuracy: 0.2698\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 222.9131 - accuracy: 0.2692\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 237.0109 - accuracy: 0.9926\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=32; total time=28.3min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 86s 44ms/step - loss: 1.1826 - accuracy: 0.2980\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 1.8175 - accuracy: 0.2723\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 80s 41ms/step - loss: 2.5869 - accuracy: 0.3983\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 4.4285 - accuracy: 0.3815\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 6.9667 - accuracy: 0.3614\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 9.6360 - accuracy: 0.3306\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 13.6028 - accuracy: 0.3199\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 17.6440 - accuracy: 0.3015 0s - loss: 17.6641 - accuracy: 0.\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 86s 44ms/step - loss: 22.4814 - accuracy: 0.2912\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 84s 43ms/step - loss: 27.9635 - accuracy: 0.2815\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 33.9975 - accuracy: 0.2776\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 97s 50ms/step - loss: 40.9841 - accuracy: 0.2747\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 47.4994 - accuracy: 0.2716\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 80s 42ms/step - loss: 54.6699 - accuracy: 0.2692\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 80s 41ms/step - loss: 62.9473 - accuracy: 0.2671\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 79s 41ms/step - loss: 72.2835 - accuracy: 0.2643\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 80.8717 - accuracy: 0.2628 1s - loss: 80.6225 -\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 91.3737 - accuracy: 0.2639\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 101.3567 - accuracy: 0.2642\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 113.8865 - accuracy: 0.2584\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 129.4121 - accuracy: 0.2457\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=32; total time=28.5min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 1.1005 - accuracy: 0.3685\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 2.0717 - accuracy: 0.2925\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 3.9979 - accuracy: 0.4150\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 6.9855 - accuracy: 0.3909\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 11.3102 - accuracy: 0.3667 6s - lo - ETA: 4s  - ETA: 1s - loss: 11.173\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 90s 46ms/step - loss: 16.0992 - accuracy: 0.3479\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 21.5018 - accuracy: 0.3270\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 82s 43ms/step - loss: 28.1823 - accuracy: 0.3062\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 80s 41ms/step - loss: 36.9739 - accuracy: 0.3000\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 44.4168 - accuracy: 0.2887\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 53.1487 - accuracy: 0.2834 2s - loss\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 63.7764 - accuracy: 0.2792\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 73.1987 - accuracy: 0.2737\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 84.5246 - accuracy: 0.2726\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 94s 48ms/step - loss: 95.8498 - accuracy: 0.2750\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 109.8845 - accuracy: 0.2697\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 93s 48ms/step - loss: 122.7360 - accuracy: 0.2670\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 136.7555 - accuracy: 0.2686\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 92s 48ms/step - loss: 153.4327 - accuracy: 0.2618\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 168.2124 - accuracy: 0.2669\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 184.5015 - accuracy: 0.9946\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=32; total time=30.6min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 98s 51ms/step - loss: 1.2530 - accuracy: 0.3041\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 95s 49ms/step - loss: 2.2828 - accuracy: 0.2688\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 84s 43ms/step - loss: 3.7846 - accuracy: 0.4226\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 84s 43ms/step - loss: 6.4704 - accuracy: 0.4050\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 10.4163 - accuracy: 0.3709\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 14.7979 - accuracy: 0.3464\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 20.2601 - accuracy: 0.3207\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 80s 42ms/step - loss: 26.2552 - accuracy: 0.3114 0s - loss: 26.1417 - accu\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 33.4406 - accuracy: 0.2956\n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 41.1801 - accuracy: 0.2906 4s - loss: 40.7312 - \n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 51.3737 - accuracy: 0.2879\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 59.9973 - accuracy: 0.2804\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 88s 45ms/step - loss: 71.4284 - accuracy: 0.2776\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 87s 45ms/step - loss: 82.7235 - accuracy: 0.2734\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 93.7535 - accuracy: 0.2735\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 105.8330 - accuracy: 0.26932s - loss:\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 121.7559 - accuracy: 0.2676\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 133.0802 - accuracy: 0.2680\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 81s 42ms/step - loss: 149.0224 - accuracy: 0.2649\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 167.9064 - accuracy: 0.2632\n",
            "483/483 [==============================] - 1s 1ms/step - loss: 151.5230 - accuracy: 0.2828\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=32; total time=28.5min\n",
            "Epoch 1/20\n",
            "1932/1932 [==============================] - 88s 46ms/step - loss: 1.1030 - accuracy: 0.2602\n",
            "Epoch 2/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 2.1931 - accuracy: 0.3021\n",
            "Epoch 3/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 4.2853 - accuracy: 0.4646\n",
            "Epoch 4/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 7.3443 - accuracy: 0.4181\n",
            "Epoch 5/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 11.4885 - accuracy: 0.3770\n",
            "Epoch 6/20\n",
            "1932/1932 [==============================] - 80s 41ms/step - loss: 16.4219 - accuracy: 0.3422 0s - loss: 16.4023 - accuracy: 0.\n",
            "Epoch 7/20\n",
            "1932/1932 [==============================] - 82s 42ms/step - loss: 22.5635 - accuracy: 0.3300\n",
            "Epoch 8/20\n",
            "1932/1932 [==============================] - 80s 42ms/step - loss: 29.1644 - accuracy: 0.3125\n",
            "Epoch 9/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 36.8496 - accuracy: 0.2969 7s - loss: 36.6879 - accuracy: 0. - ETA: 7s - loss: 36.7058  - ETA: 6s - loss: 36.9311 - accuracy - ETA: 6s \n",
            "Epoch 10/20\n",
            "1932/1932 [==============================] - 85s 44ms/step - loss: 45.9422 - accuracy: 0.2968\n",
            "Epoch 11/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 54.8430 - accuracy: 0.2860\n",
            "Epoch 12/20\n",
            "1932/1932 [==============================] - ETA: 0s - loss: 64.3413 - accuracy: 0.279 - 87s 45ms/step - loss: 64.3769 - accuracy: 0.2796\n",
            "Epoch 13/20\n",
            "1932/1932 [==============================] - 83s 43ms/step - loss: 76.9581 - accuracy: 0.2758\n",
            "Epoch 14/20\n",
            "1932/1932 [==============================] - 86s 45ms/step - loss: 87.7698 - accuracy: 0.2722\n",
            "Epoch 15/20\n",
            "1932/1932 [==============================] - 80s 42ms/step - loss: 98.2392 - accuracy: 0.2757\n",
            "Epoch 16/20\n",
            "1932/1932 [==============================] - 79s 41ms/step - loss: 113.4024 - accuracy: 0.2720\n",
            "Epoch 17/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 125.3396 - accuracy: 0.2685\n",
            "Epoch 18/20\n",
            "1932/1932 [==============================] - 90s 47ms/step - loss: 141.5627 - accuracy: 0.2691\n",
            "Epoch 19/20\n",
            "1932/1932 [==============================] - 89s 46ms/step - loss: 156.9327 - accuracy: 0.2671\n",
            "Epoch 20/20\n",
            "1932/1932 [==============================] - 91s 47ms/step - loss: 170.0966 - accuracy: 0.2659\n",
            "  1/483 [..............................] - ETA: 0s - loss: 0.1895 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0051s). Check your callbacks.\n",
            "483/483 [==============================] - 1s 2ms/step - loss: 167.0494 - accuracy: 0.0331\n",
            "[CV] END ......................epochs=20, lr=0.002, nodes=32; total time=28.5min\n",
            "Epoch 1/20\n",
            "2415/2415 [==============================] - 105s 43ms/step - loss: 1.3900 - accuracy: 0.2715\n",
            "Epoch 2/20\n",
            "2415/2415 [==============================] - 102s 42ms/step - loss: 2.8261 - accuracy: 0.3462\n",
            "Epoch 3/20\n",
            "2415/2415 [==============================] - 101s 42ms/step - loss: 5.9352 - accuracy: 0.4079\n",
            "Epoch 4/20\n",
            "2415/2415 [==============================] - 102s 42ms/step - loss: 10.3539 - accuracy: 0.35711s - loss: 10.3459 \n",
            "Epoch 5/20\n",
            "2415/2415 [==============================] - 99s 41ms/step - loss: 15.7931 - accuracy: 0.3304\n",
            "Epoch 6/20\n",
            "2415/2415 [==============================] - 101s 42ms/step - loss: 23.0319 - accuracy: 0.3116\n",
            "Epoch 7/20\n",
            "2415/2415 [==============================] - 104s 43ms/step - loss: 30.7318 - accuracy: 0.3036\n",
            "Epoch 8/20\n",
            "2415/2415 [==============================] - 110s 46ms/step - loss: 39.5969 - accuracy: 0.2885\n",
            "Epoch 9/20\n",
            "2415/2415 [==============================] - 106s 44ms/step - loss: 50.4557 - accuracy: 0.2838\n",
            "Epoch 10/20\n",
            "2415/2415 [==============================] - 103s 43ms/step - loss: 60.1505 - accuracy: 0.2784\n",
            "Epoch 11/20\n",
            "2415/2415 [==============================] - 106s 44ms/step - loss: 72.6188 - accuracy: 0.2727\n",
            "Epoch 12/20\n",
            "2415/2415 [==============================] - 105s 44ms/step - loss: 86.4559 - accuracy: 0.2716\n",
            "Epoch 13/20\n",
            "2415/2415 [==============================] - 108s 45ms/step - loss: 99.7301 - accuracy: 0.2647\n",
            "Epoch 14/20\n",
            "2415/2415 [==============================] - 107s 44ms/step - loss: 115.8669 - accuracy: 0.2641\n",
            "Epoch 15/20\n",
            "2415/2415 [==============================] - 107s 44ms/step - loss: 132.1884 - accuracy: 0.2646\n",
            "Epoch 16/20\n",
            "2415/2415 [==============================] - 108s 45ms/step - loss: 144.6408 - accuracy: 0.2632\n",
            "Epoch 17/20\n",
            "2415/2415 [==============================] - 111s 46ms/step - loss: 168.4510 - accuracy: 0.2617\n",
            "Epoch 18/20\n",
            "2415/2415 [==============================] - 112s 47ms/step - loss: 183.4028 - accuracy: 0.2618\n",
            "Epoch 19/20\n",
            "2415/2415 [==============================] - 110s 46ms/step - loss: 209.4970 - accuracy: 0.2612\n",
            "Epoch 20/20\n",
            "2415/2415 [==============================] - 110s 45ms/step - loss: 221.1757 - accuracy: 0.2596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v8qgSRRcEui",
        "outputId": "14beeb2c-bbba-433f-b8d4-e57ae7c07041"
      },
      "source": [
        "print(grid_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000001FDA255AAF0>,\n",
            "             n_jobs=1,\n",
            "             param_grid={'epochs': [10, 20], 'lr': [0.001, 0.002],\n",
            "                         'nodes': [16, 32]},\n",
            "             verbose=2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5DDtFowucEuj",
        "outputId": "0ce83f75-afea-4e1d-b6aa-7ba5de1f18f4"
      },
      "source": [
        "print('Best estimator : {}'.format(grid.best_estimator_))\n",
        "print('Best score : {}'.format(grid.best_score_))\n",
        "print('Best params : {}'.format(grid.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best estimator : <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000001FDAA8A9220>\n",
            "Best score : 0.5097691133618355\n",
            "Best params : {'epochs': 20, 'lr': 0.002, 'nodes': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcQLuF0JcEuj",
        "outputId": "7184043c-a011-4db2-fb6f-a0b300c36fdd"
      },
      "source": [
        "print(grid.cv_results_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mean_fit_time': array([ 494.86758976,  882.14677353,  477.9971127 ,  916.88046474,\n",
            "        946.94261413, 1797.00441146,  962.86820879, 1724.06636071]), 'std_fit_time': array([ 6.54266998,  9.04356508,  8.03429174, 20.39105651,  7.34210253,\n",
            "       31.10282033, 82.19042564, 37.26262965]), 'mean_score_time': array([1.09999709, 1.88745875, 1.04539094, 1.80274229, 2.68720894,\n",
            "       1.0985589 , 6.74938922, 8.33918695]), 'std_score_time': array([ 0.11875915,  1.84593402,  0.12939676,  0.52630865,  3.41144698,\n",
            "        0.12642677, 11.21542666, 13.54751822]), 'param_epochs': masked_array(data=[10, 10, 10, 10, 20, 20, 20, 20],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_lr': masked_array(data=[0.001, 0.001, 0.002, 0.002, 0.001, 0.001, 0.002, 0.002],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_nodes': masked_array(data=[16, 32, 16, 32, 16, 32, 16, 32],\n",
            "             mask=[False, False, False, False, False, False, False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'epochs': 10, 'lr': 0.001, 'nodes': 16}, {'epochs': 10, 'lr': 0.001, 'nodes': 32}, {'epochs': 10, 'lr': 0.002, 'nodes': 16}, {'epochs': 10, 'lr': 0.002, 'nodes': 32}, {'epochs': 20, 'lr': 0.001, 'nodes': 16}, {'epochs': 20, 'lr': 0.001, 'nodes': 32}, {'epochs': 20, 'lr': 0.002, 'nodes': 16}, {'epochs': 20, 'lr': 0.002, 'nodes': 32}], 'split0_test_score': array([0.10405746, 0.99488771, 0.0130719 , 0.0020708 , 0.03216204,\n",
            "       0.24118294, 0.04613991, 0.99255806]), 'split1_test_score': array([0.2687504 , 0.0497638 , 0.01824888, 0.03494467, 0.99262279,\n",
            "       0.99437004, 0.99437004, 0.2457128 ]), 'split2_test_score': array([0.43722495, 0.0931271 , 0.00951333, 0.99275172, 0.04879627,\n",
            "       0.02511002, 0.01041936, 0.99462855]), 'split3_test_score': array([0.05112607, 0.99430496, 0.05462076, 0.02562775, 0.00841315,\n",
            "       0.01507895, 0.00550091, 0.28281128]), 'split4_test_score': array([0.97689617, 0.10018121, 0.01941496, 0.99495208, 0.99495208,\n",
            "       0.01889723, 0.99495208, 0.03313487]), 'mean_test_score': array([0.36761101, 0.44645295, 0.02297397, 0.4100694 , 0.41538927,\n",
            "       0.25892784, 0.41027646, 0.50976911]), 'std_test_score': array([0.333308  , 0.44789018, 0.01622191, 0.47677736, 0.47243512,\n",
            "       0.3776077 , 0.47735422, 0.40412613]), 'rank_test_score': array([6, 2, 8, 5, 3, 7, 4, 1])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNTlg4B2cEuk",
        "outputId": "6df11494-6caa-47b9-f861-76f34c2beaa4"
      },
      "source": [
        "predictions = grid.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\key\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAdN8jOxcEuk",
        "outputId": "024a15c5-6e38-4509-c205-c1e1e8d801f0"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings\n",
        "predict = grid.predict_proba(X_test)\n",
        "print(predict.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38631, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HysJyPihcEul",
        "outputId": "09df2ffe-530a-449d-e68c-f1a993f71478"
      },
      "source": [
        "loss = log_loss(Y_test,predict)\n",
        "print(\"Log_loss : {}\".format(loss))\n",
        "predict = np.round(predict)\n",
        "loss = hamming_loss(Y_test,predict)\n",
        "print(\"Hamming_loss : {}\".format(loss*100))\n",
        "accuracy = accuracy_score(Y_test,predict)\n",
        "print(\"Accuracy : {}\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log_loss : 2.4157717080569445\n",
            "Hamming_loss : 19.0438594220531\n",
            "Accuracy : 0.12942973259817245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvcpRKAIcEul"
      },
      "source": [
        "import matplotlib.cm as cm\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzARxdvvcEul",
        "outputId": "22664271-7569-4ead-e8f6-108687e18b0d"
      },
      "source": [
        "x = ['BR-MultNB','BR-SVC','AD-MLkNN','BP-MLL']\n",
        "y = [3.26,2.25,4.38,19.0]\n",
        "colors = itertools.cycle(['b', 'g', 'r', 'c'])\n",
        "plt.ylabel('Hamming-Loss')\n",
        "plt.xlabel('Model-details')\n",
        "plt.xticks(rotation=90)\n",
        "for i in range(len(y)):\n",
        "    plt.bar(x[i], y[i], color=next(colors))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqL6spyqcEum",
        "outputId": "9ae88e3a-47d2-43ef-b1cb-71a556a767a8"
      },
      "source": [
        "x = ['BR-MultNB','BR-SVC','AD-MLkNN','BP-MLL']\n",
        "y = [1.92,1.71,1.26,2.41]\n",
        "colors = itertools.cycle(['b', 'g', 'r', 'c'])\n",
        "plt.ylabel('Log-Loss')\n",
        "plt.xlabel('Model-details')\n",
        "plt.xticks(rotation=90)\n",
        "for i in range(len(y)):\n",
        "    plt.bar(x[i], y[i], color=next(colors))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "JYokxD3jcEum"
      },
      "source": [
        "1.While showing among the best binary relevance method models, hamming-loss was considered because BR - SVC gave the best result.\n",
        "2.But while chosing among the best Adaptation Algorithm model, log loss was preferred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFw1h__ucEun"
      },
      "source": [
        "It was a key point to note that almost all models generated by problem transformation methods had low values of hamming losses, whereas models generated by the adaptive algorithm approach had low values of log-losses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2kj1X8mcEun",
        "outputId": "6f2b08bf-df6b-4153-fe66-ccbe636cdb41"
      },
      "source": [
        "import joblib\n",
        "file='SVC-BR.pkl'\n",
        "joblib.dump(classifier2,file)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SVC-BR.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2hglTS5cEun"
      },
      "source": [
        "## predict the output for test data through the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "9bsS2fF2KmRB",
        "outputId": "7eefaa2e-a993-4afc-d0d4-f996f269fda8"
      },
      "source": [
        "from google.colab import files\n",
        "  \n",
        "  \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-04317ac7-fa7c-4ae8-bba6-8e5172822895\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-04317ac7-fa7c-4ae8-bba6-8e5172822895\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test1.csv to test1 (2).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "W5lvxAvOcEuo",
        "outputId": "14acd002-768d-4360-9a1b-a5a4eae2ec5d"
      },
      "source": [
        "df2=pd.read_csv(\"test1 (2).csv\")\n",
        "df2.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTJ_6-k4cEup",
        "outputId": "569e3125-40e1-4a7b-bcf5-b5e6dfe6b4a7"
      },
      "source": [
        "df2.isnull().values.any()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIRWGM8ScEup"
      },
      "source": [
        "df2.drop_duplicates(inplace = True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZwWJ8ANcEup",
        "outputId": "19e50d27-ab77-4e53-c41e-a160de8c90bb"
      },
      "source": [
        "print(df2.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(153164, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSaY8YWRcEuq"
      },
      "source": [
        "df2 = df2.reindex(np.random.permutation(df2.index))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuHsO7stcEuq",
        "outputId": "efe74bf3-96b5-4d4c-f565-d58784d59a09"
      },
      "source": [
        "comment2 = df2['comment_text']\n",
        "print(comment2.head())\n",
        "comment2 = comment2.to_numpy()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87669    == My promotion to admin == \\n I was expecting...\n",
            "19854    == Jews? == \\n\\n Hello, \\n\\n Where you wrote t...\n",
            "2608     \" \\n\\n :No. Applications frequently assume tha...\n",
            "49017    I have a suggestion to alleviate this nonsense...\n",
            "48477    == Image == \\n\\n I removed the current image. ...\n",
            "Name: comment_text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YP2VTW0lcEur",
        "outputId": "73520390-caff-43a4-e963-b4fda2f27825"
      },
      "source": [
        "x2 = [len(comment2[i]) for i in range(comment2.shape[0])]\n",
        "\n",
        "print('average length of comment: {:.3f}'.format(sum(x2)/len(x2)) )\n",
        "bins = [1,200,400,600,800,1000,1200]\n",
        "plt.hist(x2, bins=bins)\n",
        "plt.xlabel('Length of comments')\n",
        "plt.ylabel('Number of comments')       \n",
        "plt.axis([0, 1200, 0, 90000])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average length of comment: 364.875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EIyN2tncEur"
      },
      "source": [
        "comments2 = []\n",
        "\n",
        "for ix in range(comment2.shape[0]):\n",
        "    if len(comment2[ix])<=400:\n",
        "        comments2.append(comment2[ix])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6nGUlykcEus",
        "outputId": "afa2a4c9-68ce-4229-8852-76f5163e4b07"
      },
      "source": [
        "print(len(comments2))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "115769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b98cX8n4cEus"
      },
      "source": [
        "for i in range(len(comments2)):\n",
        "    comments2[i] = comments2[i].lower().translate(trantab)\n",
        "    l2 = []\n",
        "    for word in comments2[i].split():\n",
        "        l2.append(stemmer.stem(lemmatiser.lemmatize(word,pos=\"v\")))\n",
        "    comments2[i] = \" \".join(l2)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIhSbxh7cEus"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#create object supplying our custom stop words\n",
        "count_vector = CountVectorizer(stop_words=stop_words)\n",
        "#fitting it to converts comments into bag of words format\n",
        "tf2 = count_vector.fit_transform(comments2).astype(np.uint8)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCmkXPP2cEut"
      },
      "source": [
        "tf2=tf2.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTw9k1EacEut",
        "outputId": "fe912c47-f784-4092-ed04-db18b16ce4f8"
      },
      "source": [
        "print(tf2.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(115769, 95799)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPlMC581cEuu"
      },
      "source": [
        "import joblib\n",
        "loadm=joblib.load('SVC-BR.pkl')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMeYuBC6cEuu"
      },
      "source": [
        "pred=loadm.predict(tf2[:,0:72292])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnuAHwKQdMqE",
        "outputId": "8612d8cd-fc1c-46eb-ad80-766e530fdb8f"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(115769, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHSceEKcEuv",
        "outputId": "4781dd1b-6dc0-4c51-8d60-f90076994b6b"
      },
      "source": [
        "evaluate_score(Y_test,pred[0:38631,:])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 88.24260309078201\n",
            "Log_loss : 0.4684932980759391\n",
            "Hamming_loss : 4.361781988558412\n",
            "Precision: 5.027183423944746\n",
            "Recall: 0.019833399444664817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLBDiBl9dDSe"
      },
      "source": [
        "pred=pd.DataFrame(pred)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSEo9R9PeD8G"
      },
      "source": [
        "pred.to_csv(\"predmcc.csv\")"
      ],
      "execution_count": 77,
      "outputs": []
    }
  ]
}